# prompt engineering framework

This is an evolutianary process. 

![Prompt Engineering](Prompt%20Engineering%20-%20Prompt%20Map.png)

## The Setup 

Setting up prompts to use the LLM effectively

- System Message -> Custom Instructions
- Persona
- Context

## The Instruction 

Be clear and specific

- Delimeters
- Instructions -> Clear & Specific X - Y Problem
- Exemplars (Zero Shot, One Shot, Few Shot)
- Chain of Though Prompt -> Zero=shot CoT *Lets think step by step*
- Token Management 
- Hyper Parameters -> Temperature, Top-p
- Consider Additional Techniques
  
## The Output

Controlling the output of the model, format, length, detail, restrictions, etc 

- Format
- Length & Detail
- Additional Restrictions

## The Evaluation

How do we trust the output? Measure accuracy and success. 

- Assess Vulnerabilities -> Hallucinations, Bias, Sources, Math
- Testing
- The most Powerful Prompt
- Iterate, Iterate, Iterate

---

# The Standard Prompt

Just a **simple Question** or an **simple Instruction** 

Nothing special here 

This is a **known term** and is used to define **only a question** or **only an instruction**

## You need to ask the right question to get the right response! 

It's kind of the same as talking to a standard human. If you don't ask a suitable question, you will be unlikely to get a suitable answer from them. 

The **standard prompt** is your basic starting place. It's kind of the block to jump off as you chat to an LLM, especially if you don't know the thing your prompting about already. 

---

# The prompt Library

This is a bit of a naff thing that people sell, a bunch of 'starter questions' for those that don't know what they're doing with an LLM. 

We don't think there's much value in this specifically. but for reference, here is the [Anthropic prompt library](https://docs.anthropic.com/en/prompt-library/library) to get you started. 

---